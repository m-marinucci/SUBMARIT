{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with SUBMARIT\n",
    "\n",
    "This notebook provides a comprehensive introduction to SUBMARIT (SUBMARket Identification and Testing).\n",
    "\n",
    "## Table of Contents\n",
    "1. [Installation and Setup](#installation)\n",
    "2. [Basic Concepts](#concepts)\n",
    "3. [Loading Data](#loading)\n",
    "4. [Creating Substitution Matrices](#substitution)\n",
    "5. [Clustering Products](#clustering)\n",
    "6. [Evaluating Results](#evaluation)\n",
    "7. [Visualization](#visualization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installation and Setup <a id='installation'></a>\n",
    "\n",
    "First, let's import the necessary libraries and set up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# SUBMARIT imports\n",
    "from submarit.core import create_substitution_matrix\n",
    "from submarit.algorithms import LocalSearch\n",
    "from submarit.evaluation import ClusterEvaluator, gap_statistic\n",
    "from submarit.evaluation.visualization import plot_substitution_matrix\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Configure visualization\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Basic Concepts <a id='concepts'></a>\n",
    "\n",
    "SUBMARIT identifies submarkets based on product substitution patterns. Key concepts:\n",
    "\n",
    "- **Substitution Matrix**: Measures how substitutable products are for each other\n",
    "- **Submarkets**: Groups of products that are close substitutes\n",
    "- **Local Search**: Algorithm that finds optimal submarket assignments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Loading Data <a id='loading'></a>\n",
    "\n",
    "Let's create a synthetic dataset representing products with various features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create synthetic product data\n",
    "n_products = 150\n",
    "n_features = 10\n",
    "\n",
    "# Generate products in 3 distinct groups\n",
    "np.random.seed(42)\n",
    "\n",
    "# Group 1: Budget products (low price, basic features)\n",
    "group1 = np.random.randn(50, n_features) * 0.5 + np.array([1, 1, 0, 0, 1, 0, 0, 1, 0, 0])\n",
    "\n",
    "# Group 2: Mid-range products\n",
    "group2 = np.random.randn(50, n_features) * 0.5 + np.array([3, 3, 1, 1, 2, 1, 1, 2, 1, 1])\n",
    "\n",
    "# Group 3: Premium products (high price, advanced features)\n",
    "group3 = np.random.randn(50, n_features) * 0.5 + np.array([5, 5, 2, 2, 3, 2, 2, 3, 2, 2])\n",
    "\n",
    "# Combine groups\n",
    "X = np.vstack([group1, group2, group3])\n",
    "\n",
    "# Create product names\n",
    "product_names = [f\"Product_{i:03d}\" for i in range(n_products)]\n",
    "\n",
    "# Create DataFrame for easier viewing\n",
    "feature_names = [f\"Feature_{i}\" for i in range(n_features)]\n",
    "df_products = pd.DataFrame(X, columns=feature_names, index=product_names)\n",
    "\n",
    "print(f\"Dataset shape: {X.shape}\")\n",
    "print(f\"\\nFirst 5 products:\")\n",
    "df_products.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature distributions\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, feature in enumerate(feature_names):\n",
    "    axes[i].hist(df_products[feature], bins=20, alpha=0.7)\n",
    "    axes[i].set_title(feature)\n",
    "    axes[i].set_xlabel('Value')\n",
    "    axes[i].set_ylabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Creating Substitution Matrices <a id='substitution'></a>\n",
    "\n",
    "The substitution matrix captures how similar/substitutable products are based on their features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create substitution matrix using Euclidean distance\n",
    "S_euclidean = create_substitution_matrix(X, metric='euclidean')\n",
    "\n",
    "print(f\"Substitution matrix shape: {S_euclidean.shape}\")\n",
    "print(f\"Value range: [{S_euclidean.min():.3f}, {S_euclidean.max():.3f}]\")\n",
    "print(f\"Mean substitution distance: {S_euclidean.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different distance metrics\n",
    "metrics = ['euclidean', 'manhattan', 'cosine']\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    S = create_substitution_matrix(X, metric=metric)\n",
    "    \n",
    "    im = axes[i].imshow(S, cmap='viridis', aspect='auto')\n",
    "    axes[i].set_title(f'{metric.capitalize()} Distance')\n",
    "    axes[i].set_xlabel('Product Index')\n",
    "    axes[i].set_ylabel('Product Index')\n",
    "    plt.colorbar(im, ax=axes[i])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Clustering Products <a id='clustering'></a>\n",
    "\n",
    "Now let's identify submarkets using the Local Search algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's find the optimal number of clusters using gap statistic\n",
    "print(\"Finding optimal number of clusters...\")\n",
    "\n",
    "k_values = range(2, 8)\n",
    "gaps = []\n",
    "stds = []\n",
    "\n",
    "for k in k_values:\n",
    "    gap, std = gap_statistic(S_euclidean, k, n_bootstrap=10)\n",
    "    gaps.append(gap)\n",
    "    stds.append(std)\n",
    "    print(f\"k={k}: gap={gap:.3f}, std={std:.3f}\")\n",
    "\n",
    "# Plot gap statistic\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.errorbar(k_values, gaps, yerr=stds, marker='o', capsize=5)\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Gap Statistic')\n",
    "plt.title('Gap Statistic for Optimal k')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform clustering with k=3 (our true number of groups)\n",
    "n_clusters = 3\n",
    "\n",
    "# Initialize Local Search algorithm\n",
    "ls = LocalSearch(\n",
    "    n_clusters=n_clusters,\n",
    "    max_iter=100,\n",
    "    n_restarts=10,\n",
    "    random_state=42,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "clusters = ls.fit_predict(S_euclidean)\n",
    "\n",
    "print(f\"\\nClustering complete!\")\n",
    "print(f\"Final objective value: {ls.objective_:.3f}\")\n",
    "print(f\"Number of iterations: {ls.n_iter_}\")\n",
    "print(f\"Cluster sizes: {np.bincount(clusters)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze cluster assignments\n",
    "df_products['Cluster'] = clusters\n",
    "\n",
    "# Show cluster means\n",
    "cluster_means = df_products.groupby('Cluster')[feature_names].mean()\n",
    "print(\"Cluster feature means:\")\n",
    "cluster_means.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluating Results <a id='evaluation'></a>\n",
    "\n",
    "Let's evaluate the quality of our clustering using various metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize evaluator\n",
    "evaluator = ClusterEvaluator()\n",
    "\n",
    "# Calculate all metrics\n",
    "metrics = evaluator.evaluate(S_euclidean, clusters)\n",
    "\n",
    "# Display results\n",
    "print(\"Clustering Quality Metrics:\")\n",
    "print(\"=\" * 40)\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"{metric:20s}: {value:10.4f}\")\n",
    "\n",
    "# Interpret results\n",
    "print(\"\\nInterpretation:\")\n",
    "print(f\"- Silhouette score: {metrics['silhouette']:.3f} (closer to 1 is better)\")\n",
    "print(f\"- Davies-Bouldin: {metrics['davies_bouldin']:.3f} (lower is better)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different numbers of clusters\n",
    "k_range = range(2, 8)\n",
    "silhouette_scores = []\n",
    "db_scores = []\n",
    "\n",
    "for k in k_range:\n",
    "    ls_temp = LocalSearch(n_clusters=k, n_restarts=5, random_state=42)\n",
    "    clusters_temp = ls_temp.fit_predict(S_euclidean)\n",
    "    metrics_temp = evaluator.evaluate(S_euclidean, clusters_temp)\n",
    "    \n",
    "    silhouette_scores.append(metrics_temp['silhouette'])\n",
    "    db_scores.append(metrics_temp['davies_bouldin'])\n",
    "\n",
    "# Plot comparison\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "ax1.plot(k_range, silhouette_scores, 'o-', markersize=8)\n",
    "ax1.set_xlabel('Number of Clusters')\n",
    "ax1.set_ylabel('Silhouette Score')\n",
    "ax1.set_title('Silhouette Score vs Number of Clusters')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "ax2.plot(k_range, db_scores, 'o-', markersize=8, color='orange')\n",
    "ax2.set_xlabel('Number of Clusters')\n",
    "ax2.set_ylabel('Davies-Bouldin Index')\n",
    "ax2.set_title('Davies-Bouldin Index vs Number of Clusters')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualization <a id='visualization'></a>\n",
    "\n",
    "Finally, let's visualize our submarkets in various ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot substitution matrix with cluster boundaries\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "plot_substitution_matrix(S_euclidean, clusters, ax=ax)\n",
    "ax.set_title('Substitution Matrix with Identified Submarkets', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize clusters in 2D using PCA\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Reduce to 2D\n",
    "pca = PCA(n_components=2)\n",
    "X_2d = pca.fit_transform(X)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "scatter = plt.scatter(X_2d[:, 0], X_2d[:, 1], c=clusters, \n",
    "                     cmap='viridis', s=100, alpha=0.7, edgecolors='black')\n",
    "plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} variance)')\n",
    "plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%} variance)')\n",
    "plt.title('Products in 2D PCA Space', fontsize=16)\n",
    "plt.colorbar(scatter, label='Cluster')\n",
    "\n",
    "# Add cluster centers\n",
    "for k in range(n_clusters):\n",
    "    cluster_points = X_2d[clusters == k]\n",
    "    center = cluster_points.mean(axis=0)\n",
    "    plt.plot(center[0], center[1], 'r*', markersize=20, \n",
    "             markeredgecolor='black', markeredgewidth=2)\n",
    "\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a heatmap of average features by cluster\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(cluster_means.T, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "            cbar_kws={'label': 'Average Value'})\n",
    "plt.xlabel('Cluster', fontsize=12)\n",
    "plt.ylabel('Feature', fontsize=12)\n",
    "plt.title('Average Feature Values by Cluster', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive cluster exploration\n",
    "from ipywidgets import interact, IntSlider\n",
    "\n",
    "def explore_cluster(cluster_id):\n",
    "    \"\"\"Explore products in a specific cluster.\"\"\"\n",
    "    mask = clusters == cluster_id\n",
    "    cluster_products = df_products[mask]\n",
    "    \n",
    "    print(f\"Cluster {cluster_id} - {mask.sum()} products\")\n",
    "    print(\"=\" * 50)\n",
    "    print(\"\\nFeature statistics:\")\n",
    "    print(cluster_products[feature_names].describe().round(2))\n",
    "    \n",
    "    print(\"\\nSample products:\")\n",
    "    print(cluster_products.head(10))\n",
    "\n",
    "# Create interactive widget\n",
    "interact(explore_cluster, \n",
    "         cluster_id=IntSlider(min=0, max=n_clusters-1, step=1, value=0,\n",
    "                             description='Cluster:'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we've covered:\n",
    "\n",
    "1. **Data Preparation**: Creating a synthetic dataset with distinct product groups\n",
    "2. **Substitution Matrix**: Computing product similarities using different metrics\n",
    "3. **Clustering**: Using Local Search to identify submarkets\n",
    "4. **Evaluation**: Assessing cluster quality with multiple metrics\n",
    "5. **Visualization**: Various ways to visualize and interpret results\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Try with your own data\n",
    "- Experiment with different distance metrics\n",
    "- Explore advanced features like cross-validation and stability analysis\n",
    "- Check out the other example notebooks for more advanced usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results for later use\n",
    "results = {\n",
    "    'data': X,\n",
    "    'product_names': product_names,\n",
    "    'substitution_matrix': S_euclidean,\n",
    "    'clusters': clusters,\n",
    "    'metrics': metrics,\n",
    "    'algorithm_params': {\n",
    "        'n_clusters': n_clusters,\n",
    "        'metric': 'euclidean',\n",
    "        'algorithm': 'local_search'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save to file (optional)\n",
    "# import joblib\n",
    "# joblib.dump(results, 'getting_started_results.pkl')\n",
    "\n",
    "print(\"Analysis complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}